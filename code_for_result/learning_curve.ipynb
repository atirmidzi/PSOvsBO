{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9df737d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "import math\n",
    "import quantecon as qe\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import WhiteKernel, RBF\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e9e908",
   "metadata": {
    "code_folding": [
     0,
     79,
     134,
     187
    ]
   },
   "outputs": [],
   "source": [
    "def create_bayesian_table(directory, name, experiment_per_generation, experiments, elements, activity, factor = 1):\n",
    "    df = pd.read_csv(str(directory) + str(name) + '.txt', sep='\\t')\n",
    "    df = df[0:experiments]\n",
    "    x_old = df[elements].to_numpy()\n",
    "    x_old = np.around(x_old, decimals = 3)\n",
    "    \n",
    "    ID = list(range(1, experiment_per_generation+1))*(math.ceil(len(df)/experiment_per_generation))\n",
    "    ID = np.array(ID[0:len(df)])\n",
    "\n",
    "    gen = []\n",
    "    for i in range(math.ceil(len(df)/experiment_per_generation)):\n",
    "        gen.append([i]*experiment_per_generation)\n",
    "    gen = np.array(gen)\n",
    "    gen = np.reshape(gen, -1)\n",
    "    gen = gen[0:len(df)]\n",
    "    \n",
    "    data = {'ID' : ID, 'Elements': [elements], 'Generation': gen}\n",
    "    datalog = pd.DataFrame(data=data, index = np.arange(len(df)))\n",
    "    datalog = pd.concat([datalog, pd.DataFrame(([[i] for i in x_old]), columns = ['Position'])], axis = 1)\n",
    "    datalog['Activity'] = df[str(activity)] * factor\n",
    "    return datalog\n",
    "\n",
    "def data_parity_BO(label, \n",
    "                   load_location,\n",
    "                   experiment_per_generation,\n",
    "                   total_experiments,\n",
    "                   element,\n",
    "                   grid_len,\n",
    "                   save_location,\n",
    "                   grid_location,\n",
    "                   upper_boundaries,\n",
    "                   max_activity,\n",
    "                   name,\n",
    "                   length_scale):\n",
    "    datalog = create_bayesian_table(directory = '../raw_data/composition_vs_activity/' + load_location,\n",
    "                                    name = label,\n",
    "                                    experiment_per_generation = experiment_per_generation,\n",
    "                                    experiments = total_experiments,\n",
    "                                    elements = element,\n",
    "                                    activity = 'Activity',\n",
    "                                    factor = -1)\n",
    "\n",
    "\n",
    "\n",
    "    #Preaparing data for fitting\n",
    "    x = []\n",
    "    for i in range(len(datalog)):\n",
    "        x.append(list(datalog['Position'][i]))\n",
    "    x = np.array(x)\n",
    "    y = datalog['Activity'].to_numpy()\n",
    "\n",
    "    #GPR model\n",
    "    kernel = RBF(length_scale = length_scale, length_scale_bounds = 'fixed') + WhiteKernel()\n",
    "    gpr = GaussianProcessRegressor(kernel = kernel, random_state=0, normalize_y=True).fit(x, y)\n",
    "\n",
    "    #Create Grid Data based on GPR\n",
    "    elements = len(element)\n",
    "    grid_len = grid_len\n",
    "    grid = qe.simplex_grid(elements, grid_len)/grid_len\n",
    "    element = element\n",
    "\n",
    "    act = []\n",
    "    for i in grid:\n",
    "        act.append(float(gpr.predict(np.reshape(i, (1, -1)))))\n",
    "    data_grid = pd.DataFrame(grid, columns = [element])\n",
    "    data_grid = data_grid.assign(Activity = act)\n",
    "    data_grid.to_csv(save_location, sep='\\t', mode='w')\n",
    "\n",
    "    #Try to remove the data outside the boundaries\n",
    "    df = pd.read_csv(save_location, sep='\\t')\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    for i in element:\n",
    "        df = df.drop(df[df[i] > upper_boundaries].index)\n",
    "\n",
    "    #Index need to be removed after removing some \n",
    "    df = df.reset_index(drop='True')\n",
    "\n",
    "    #Real Grid\n",
    "    real_grid = pd.read_csv(grid_location, sep='\\t')\n",
    "    real_grid = real_grid.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    for i in element:\n",
    "        real_grid = real_grid.drop(real_grid[real_grid[i] > upper_boundaries].index)\n",
    "\n",
    "    #Index need to be removed after removing some \n",
    "    real_grid = real_grid.reset_index(drop='True')\n",
    "    \n",
    "    #Converting result in np.array\n",
    "    result = np.array([real_grid['Activity'], df['Activity']])\n",
    "    result = result.T\n",
    "    result = abs(result/max_activity)\n",
    "    length_scale = float(str(gpr.kernel_).split(\"length_scale=\")[1].split(\")\")[0])\n",
    "    return result, length_scale\n",
    "\n",
    "\n",
    "def data_parity_PSO(load_location,\n",
    "                    data_number,\n",
    "                    element,\n",
    "                    grid_len,\n",
    "                    save_location,\n",
    "                    grid_location,\n",
    "                    upper_boundaries,\n",
    "                    max_activity, name,\n",
    "                    length_scale_bounds,\n",
    "                    length_scale = 1):\n",
    "    #Loading datalog\n",
    "    datalog = pd.read_csv('../raw_data/composition_vs_activity/' + load_location, sep='\\t')\n",
    "\n",
    "    #Reading \"Elements\" columns from string to list\n",
    "    datalog['Elements'] = datalog[\"Elements\"].apply(lambda x: literal_eval(x))\n",
    "\n",
    "    #Creating np.array of \"Position\" column and dropping the string type \"Position\" column\n",
    "    position = []\n",
    "    for k in range(len(datalog)):\n",
    "        position.append(list(np.fromstring(datalog['Position'][k][1:-1], dtype=float, sep=' ')))\n",
    "    position = np.array(position)\n",
    "    datalog = datalog.drop(columns=['Position'])\n",
    "    datalog = pd.concat([datalog, pd.DataFrame(([[k] for k in position]), columns = ['Position'])], axis = 1)\n",
    "\n",
    "    datalog = datalog.loc[0:data_number]\n",
    "\n",
    "\n",
    "    #Preparing data for fitting\n",
    "    x = []\n",
    "    for i in range(len(datalog)):\n",
    "        x.append(list(datalog['Position'][i]))\n",
    "    x = np.array(x)\n",
    "    y = datalog['Activity'].to_numpy()\n",
    "\n",
    "    #GPR model\n",
    "    kernel = RBF(length_scale = length_scale, length_scale_bounds = length_scale_bounds) + WhiteKernel()\n",
    "    gpr = GaussianProcessRegressor(kernel = kernel, random_state=0, normalize_y=True).fit(x, y)\n",
    "\n",
    "    \n",
    "    #Create Grid Data based on GPR\n",
    "    grid_len = grid_len\n",
    "    grid = qe.simplex_grid(len(element), grid_len)/grid_len\n",
    "    element = element\n",
    "\n",
    "    act = []\n",
    "    for i in grid:\n",
    "        act.append(float(gpr.predict(np.reshape(i, (1, -1)))))\n",
    "    data_grid = pd.DataFrame(grid, columns = [element])\n",
    "    data_grid = data_grid.assign(Activity = act)\n",
    "    data_grid.to_csv(save_location, sep='\\t', mode='w')\n",
    "\n",
    "    #Try to remove the data outside the boundaries\n",
    "    df = pd.read_csv(save_location, sep='\\t')\n",
    "    df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    for i in element:\n",
    "        df = df.drop(df[df[i] > upper_boundaries].index)\n",
    "\n",
    "    #Index need to be removed after removing some \n",
    "    df = df.reset_index(drop='True')\n",
    "\n",
    "    #Real Grid\n",
    "    real_grid = pd.read_csv(grid_location, sep='\\t')\n",
    "    real_grid = real_grid.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "    for i in element:\n",
    "        real_grid = real_grid.drop(real_grid[real_grid[i] > upper_boundaries].index)\n",
    "\n",
    "    #Index need to be removed after removing some \n",
    "    real_grid = real_grid.reset_index(drop='True')\n",
    "    \n",
    "    #Converting result in np.array\n",
    "    result = np.array([real_grid['Activity'], df['Activity']])\n",
    "    result = result.T\n",
    "    result = abs(result/max_activity)\n",
    "    length_scale = float(str(gpr.kernel_).split(\"length_scale=\")[1].split(\")\")[0])\n",
    "    return result, length_scale\n",
    "\n",
    "\n",
    "def calculate_error(result):\n",
    "    #Calculating MAE\n",
    "    GP_AE = abs(result[:, 0] - result[:, 1])\n",
    "    mae = round(GP_AE.mean(), 4)\n",
    "    \n",
    "    #Calculating R-squared\n",
    "    r_square = round(r2_score(result[:, 1], result[:, 0]), 3)\n",
    "    \n",
    "    #Calculating RMSE\n",
    "    rmse = round(np.sqrt(mean_squared_error(result[:, 1], result[:, 0])), 4)\n",
    "    \n",
    "    return np.array([mae, r_square, rmse])\n",
    "\n",
    "\n",
    "def learning_curve(method, data_type, model, data_number, data_number_8D):\n",
    "    n = model\n",
    "    if n == 3:\n",
    "        data_number = data_number_8D\n",
    "    else:\n",
    "        data_number = data_number\n",
    "    \n",
    "    for j in range(len(data_number)):\n",
    "        globals()[f\"learn_{j}\"] = pd.read_csv('../result/LS_optimization/' +\n",
    "                                              str(data_type) +  '/' + str(method) +\n",
    "                                              '_model_' + str(n+1) + \n",
    "                                              '_data_number_' + str(data_number[j]) + '.txt', sep='\\t')\n",
    "\n",
    "\n",
    "    #Selecting best length scale, and creating variables for plotting\n",
    "    chosen_length_scale = []\n",
    "    for i in range(len(data_number)):\n",
    "        chosen_length_scale.append(globals()['learn_' + str((i))].iloc[np.where(globals()['learn_' + str((i))]['MAE'] == globals()['learn_' + str((i))]['MAE'].min())[0].max()]['Length Scale'])\n",
    "    chosen_length_scale = np.array(chosen_length_scale)\n",
    "    \n",
    "    \n",
    "    \n",
    "    if data_type == 'PSO':\n",
    "        if n == 3:\n",
    "            grid_location = '../result/grid_data/' + str(models[n]) + '/grid_data_9.txt'\n",
    "        else:\n",
    "            grid_location = '../result/grid_data/' + str(models[n]) + '/grid_data_19.txt'\n",
    "        length_scale = []\n",
    "        mae = []\n",
    "        r_square = []\n",
    "        rmse = []\n",
    "        for i in range(len(data_number)): \n",
    "            parity_data = data_parity_PSO(load_location = str(models[n]) + data_location,\n",
    "                                          data_number = data_number[i],\n",
    "                                          element = elements[n],\n",
    "                                          grid_len = grid_len[n],\n",
    "                                          save_location = '../result/grid_data/' + str(models[n]) + '/grid_data_gpr.txt',\n",
    "                                          grid_location = grid_location,\n",
    "                                          upper_boundaries = upper_boundaries[n],\n",
    "                                          max_activity = max_activity[n],\n",
    "                                          name = name[n],\n",
    "                                          length_scale = chosen_length_scale[i],\n",
    "                                          length_scale_bounds = 'fixed')\n",
    "            length_scale.append(parity_data[1])\n",
    "            mae.append(calculate_error(parity_data[0])[0])\n",
    "            r_square.append(calculate_error(parity_data[0])[1])\n",
    "            rmse.append(calculate_error(parity_data[0])[2])\n",
    "    \n",
    "    if data_type == 'BO':\n",
    "        if n == 3:\n",
    "            grid_location = '../result/grid_data/' + str(models[n]) + '/grid_data_9.txt'\n",
    "        else:\n",
    "            grid_location = '../result/grid_data/' + str(models[n]) + '/grid_data_19.txt'\n",
    "        length_scale = []\n",
    "        mae = []\n",
    "        r_square = []\n",
    "        rmse = []\n",
    "        for i in range(len(data_number)):\n",
    "            parity_data = data_parity_BO(label = 'result_0',\n",
    "                                           load_location = str(models[n]) + '/BO/',\n",
    "                                           experiment_per_generation = 1,\n",
    "                                           total_experiments = data_number[i],\n",
    "                                           element = elements[n],\n",
    "                                           grid_len = grid_len[n],\n",
    "                                           save_location = '../result/grid_data/' + str(models[n]) + '/grid_data_gpr_bayes.txt',\n",
    "                                           grid_location = grid_location,\n",
    "                                           upper_boundaries = upper_boundaries[n],\n",
    "                                           max_activity = max_activity[n],\n",
    "                                           name = name[n],\n",
    "                                           length_scale = chosen_length_scale[i])\n",
    "            length_scale.append(parity_data[1])\n",
    "            mae.append(calculate_error(parity_data[0])[0])\n",
    "            r_square.append(calculate_error(parity_data[0])[1])\n",
    "            rmse.append(calculate_error(parity_data[0])[2])\n",
    "    \n",
    "    df = pd.DataFrame({'Samples': data_number, 'Length Scale': length_scale, 'MAE': mae, 'R_square': r_square, 'RMSE': rmse})\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e34d7585",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['model1', 'model2', 'model3', 'model4']\n",
    "elements = [['Ag','Ir','Pd','Pt','Ru'], ['Ag','Ir','Pd','Pt','Ru'], ['Ir','Pd','Pt','Rh','Ru'], ['Pt','Pd','Au','Ru','Rh','Ir','Re','Os']]\n",
    "max_activity = [0.163182, 0.213387, 0.167831, 1.039926]\n",
    "name = ['PSO Neural Network', 'PSO DFT [Ag,Ir,Pd,Pt,Ru]', 'PSO DFT [Ir,Pd,Pt,Rh,Ru]', 'PSO Experimental']\n",
    "scale = np.arange(0.1, 0.55, 0.02)\n",
    "upper_boundaries = [0.8, 1, 1, 1]\n",
    "grid_len = [20, 20, 20, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f7e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "85677ad6",
   "metadata": {},
   "source": [
    "# Learning Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fbc3479",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "method = 'k-fold_random'\n",
    "data_type = 'PSO'\n",
    "data_number_LC = np.linspace(15, 100, 18).astype(int)\n",
    "data_number_LC_8D = np.linspace(24, 160, 18).astype(int)\n",
    "for n in range(4):\n",
    "    model = n\n",
    "    #HP 3 is chosen -> str(2)\n",
    "    data_location = '/PSO/PSO_' + str(2) + '_0.txt'\n",
    "    globals()['learn_data_' + str(n)] = learning_curve(method, data_type, model, data_number_LC, data_number_LC_8D)\n",
    "    globals()['learn_data_' + str(n)].to_csv('../result/learning_curve/model' + str(n+1) + '/pso.txt', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26617742",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "c:\\Users\\atirm\\anaconda3\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__noise_level is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "method = 'k-fold_random'\n",
    "data_type = 'BO'\n",
    "data_number_LC = np.linspace(15, 100, 18).astype(int)\n",
    "data_number_LC_8D = np.linspace(24, 160, 18).astype(int)\n",
    "for n in range(4):\n",
    "    model = n\n",
    "    globals()['learn_data_' + str(4+n)] = learning_curve(method, data_type, model, data_number_LC, data_number_LC_8D)\n",
    "    globals()['learn_data_' + str(4+n)].to_csv('../result/learning_curve/model' + str(n+1) + '/bo.txt', sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
