{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d58cca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import quantecon as qe\n",
    "from ast import literal_eval\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "sys.path.append(r'D:\\OneDrive - Universitaet Bern\\Documents\\Others model\\Jack Model\\1_AgIrPdPtRu\\1_AgIrPdPtRu\\3_grid_search')\n",
    "import grid_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6117c1d",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Making Class\n",
    "class pso:\n",
    "    def __init__ (self, data, comparison, model_type, initial_magnitude_limit = 0.20, kicking_multiplier = 0.7, target = None, grid_distance = 0.07, boundaries = [0, 1], decimals = 3):\n",
    "        self.datalog = data\n",
    "        self.lower_boundary = boundaries[0]\n",
    "        self.upper_boundary = boundaries[1]\n",
    "        self.decimals = decimals\n",
    "        self.comparison = comparison\n",
    "        self.model_type = model_type\n",
    "        self.kicking_multiplier = kicking_multiplier\n",
    "        self.grid_distance = grid_distance\n",
    "        \n",
    "        #Reading \"Elements\" columns from string to list\n",
    "        self.datalog['Elements'] = self.datalog[\"Elements\"].apply(lambda x: literal_eval(x))\n",
    "        \n",
    "        #Select latest generation\n",
    "        self.generation = self.datalog['Generation'].max()\n",
    "        \n",
    "        #Creating np.array of \"Position\" column and dropping the string type \"Position\" column\n",
    "        self.position = []\n",
    "        for i in range(len(self.datalog)):\n",
    "            self.position.append(list(np.fromstring(self.datalog['Position'][i][1:-1], dtype=float, sep=' ')))\n",
    "        self.position = np.array(self.position)\n",
    "        #Checking whether the positions are out of boundaries or not\n",
    "        for i in range(len(self.datalog)):    \n",
    "            #Bouncing process if the position in the outside of the spaces\n",
    "            if self.position[i].max() > self.upper_boundary or self.position[i].min() < self.lower_boundary:\n",
    "                #Correcting the position\n",
    "                self.position[i] = self.correct_position(self.position[i])\n",
    "        #Putting the array into the dataframe\n",
    "        self.datalog = self.datalog.drop(columns=['Position'])\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.position]), columns = ['Position'])], axis = 1)\n",
    "        \n",
    "        #Creating target vector\n",
    "        if target == None:\n",
    "            target = []\n",
    "            for i in range(len(self.datalog['Elements'][0])):\n",
    "                target.append(1/len(self.datalog['Elements'][0]))\n",
    "            target = np.array(target)\n",
    "            target = np.around(target, decimals = self.decimals)\n",
    "        \n",
    "        #Creating \"Velocity\" column for the \"0\" generation\n",
    "        if self.generation == 0:\n",
    "            self.velocity = np.around((target - self.position), decimals = self.decimals)\n",
    "            #Turning velocity into unit vector with certain magnitude\n",
    "            self.velocity = self.initial_unit_vector_velocity(initial_magnitude_limit)\n",
    "            self.datalog = pd.concat([self.datalog, pd.DataFrame(([[i] for i in self.velocity]), columns = ['Velocity'])], axis = 1)      \n",
    "        \n",
    "        #Creating blank parameter columns\n",
    "        parameter_columns = ['F_damp', 'F_b_best', 'F_h_best', 'F_g_best', 'F_b_worst', 'F_h_worst', 'F_g_worst', 'mut_prob', 'flip_prob', 'mut_rate', 'v_max']\n",
    "        for i in parameter_columns:\n",
    "            self.datalog = pd.concat([self.datalog, pd.DataFrame(columns = [i], index = np.arange(len(self.datalog)))], axis = 1)\n",
    "\n",
    "        \n",
    "        #Creating blank \"Activity\" column\n",
    "        self.datalog = pd.concat([self.datalog, pd.DataFrame(columns = ['Activity'], index = np.arange(len(self.datalog)))], axis = 1)      \n",
    "\n",
    "               \n",
    "        #Filling the \"Activity\" column with RFR\n",
    "        self.f_activity(self.datalog)\n",
    "        \n",
    "        #Create \"Distance\" column\n",
    "        self.distance = []\n",
    "        for i in range(len(self.datalog)):\n",
    "            self.distance.append(np.sqrt(sum((self.datalog.at[i, 'Position'] - self.comparison)**2)))\n",
    "        self.distance = np.array(self.distance)\n",
    "        self.distance = np.around(self.distance, decimals = decimals)\n",
    "        self.datalog = self.datalog.assign(Distance = self.distance)\n",
    "        \n",
    "        #Creating dataframe of the latest generation\n",
    "        self.working_generation = self.datalog.loc[self.datalog['Generation']==self.generation]\n",
    "        \n",
    "        #Create Possible Optima dataframe\n",
    "        self.optima = self.datalog.loc[np.argmax(self.datalog['Activity']):np.argmax(self.datalog['Activity'])]\n",
    "    \n",
    "    def initial_unit_vector_velocity(self, initial_magnitude_limit):\n",
    "        self.unit_vector_velocity = []\n",
    "        for i in range(len(self.datalog)):\n",
    "            self.unit_vector_velocity.append(list(self.velocity[i]/np.sqrt(sum(self.velocity[i]**2))))\n",
    "        self.unit_vector_velocity = np.array(self.unit_vector_velocity)* initial_magnitude_limit\n",
    "        self.unit_vector_velocity = np.around(self.unit_vector_velocity, decimals = self.decimals)\n",
    "        return self.unit_vector_velocity\n",
    "    \n",
    "    \n",
    "    #Adjust activity with the model\n",
    "    def f_activity(self, dataframe):\n",
    "        for i in range(len(dataframe)):\n",
    "            #Correcting the possible rounding problem\n",
    "            if sum(dataframe.at[i, 'Position']) != 1:\n",
    "                dataframe.at[i, 'Position'][dataframe.at[i, 'Position'].argmax()] = dataframe.at[i, 'Position'].max() + (1 - sum(dataframe.at[i, 'Position']))\n",
    "            #Determining the activity\n",
    "            dataframe.at[i, 'Activity'] = float(grid_search.calculate_activity(metals = dataframe.at[i, 'Elements'], composition = dataframe.at[i, 'Position']))\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def input_initial_parameter(self, parameter, value, ID, behavior):\n",
    "        if behavior == 'uniform':\n",
    "            for i in range(len(self.datalog)):\n",
    "                self.datalog.at[i, parameter] = value\n",
    "        else:\n",
    "            self.datalog.at[ID, parameter] = value\n",
    "        \n",
    "        #Creating dataframe of the latest generation\n",
    "        self.working_generation = self.datalog.loc[self.datalog['Generation']==self.generation] \n",
    "        return\n",
    "\n",
    "    \n",
    "    def update_parameter(self, ID, parameter, value):\n",
    "        self.working_generation.at[ID, parameter] = value\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def create_new_velocity(self):\n",
    "        #Creating new velocity\n",
    "        for i in range(len(self.working_generation)):\n",
    "            damp_velocity = self.working_generation.at[i, 'F_damp'] * self.working_generation.at[i, 'Velocity']\n",
    "            b_best_velocity = self.working_generation.at[i, 'F_b_best'] * self.delta_individual_record(i, 'Position', 'best')\n",
    "            h_best_velocity = self.working_generation.at[i, 'F_h_best'] * self.delta_generation(i, 'Position', 'best') \n",
    "            g_best_velocity = self.working_generation.at[i, 'F_g_best'] * self.delta_global_record(i, 'Position', 'best')\n",
    "            b_worst_velocity = self.working_generation.at[i, 'F_b_worst'] * self.delta_individual_record(i, 'Position', 'worst') \n",
    "            h_worst_velocity = self.working_generation.at[i, 'F_h_worst'] * self.delta_generation(i, 'Position', 'worst')    \n",
    "            g_worst_velocity = self.working_generation.at[i, 'F_g_worst'] * self.delta_global_record(i, 'Position', 'worst')\n",
    "            \n",
    "            #Summation\n",
    "            new_velocity = (damp_velocity + b_best_velocity + h_best_velocity + g_best_velocity - b_worst_velocity - h_worst_velocity - g_worst_velocity)    \n",
    "                    \n",
    "           \n",
    "            #Mutation process\n",
    "            self.working_generation.at[i,'Velocity'] = self.mutate(new_velocity,\n",
    "                                                                   mutation_rate = self.working_generation.at[i, 'mut_rate'], \n",
    "                                                                   mutation_prob = self.working_generation.at[i, 'mut_prob'],\n",
    "                                                                   flip_prob = self.working_generation.at[i, 'flip_prob'])\n",
    "            \n",
    "        #Normalization\n",
    "        self.normalize_velocity()\n",
    "        #Limitting velocity\n",
    "        self.limitting_velocity()\n",
    "        return\n",
    "     \n",
    "    \n",
    "    def change_position(self):\n",
    "        #Changing position\n",
    "        for i in range(len(self.working_generation)):    \n",
    "            new_position = self.working_generation.at[i, 'Position'] + self.working_generation.at[i, 'Velocity']\n",
    "            #Bouncing process if the position in the outside of the spaces\n",
    "            if new_position.max() > self.upper_boundary or new_position.min() < self.lower_boundary:\n",
    "                #Bouncing the velocity\n",
    "                self.working_generation.at[i, 'Velocity'] = self.correct_velocity(new_position, self.working_generation.at[i, 'Velocity'])\n",
    "                #Correcting the position\n",
    "                new_position = self.correct_position(new_position)\n",
    "            self.working_generation.at[i,'Position'] = np.around(new_position, decimals = self.decimals)\n",
    "        return\n",
    "        \n",
    "\n",
    "    def correct_velocity(self, new_position, velocity):\n",
    "        #Changing the sign of velocity which belongs to position outside the spaces  \n",
    "        bounced_velocity_0 = np.where(new_position < self.lower_boundary, velocity * -1, velocity)\n",
    "        bounced_velocity_1 = np.where(new_position > self.upper_boundary, bounced_velocity_0 * -1, bounced_velocity_0)\n",
    "        #Normalizing the velocity\n",
    "        normalized_velocity = bounced_velocity_1 - (sum(bounced_velocity_1)/len(self.working_generation['Elements'][0]))\n",
    "        #Preserving the magnitude of velocity\n",
    "        unit_velocity = normalized_velocity/np.sqrt(sum(normalized_velocity**2))\n",
    "        corrected_velocity = unit_velocity * np.sqrt(sum(bounced_velocity_1**2))\n",
    "        corrected_velocity = np.around(corrected_velocity, decimals = self.decimals)\n",
    "        return corrected_velocity\n",
    "\n",
    "\n",
    "    def correct_position(self, new_position):\n",
    "        while new_position.max() > self.upper_boundary or new_position.min() < self.lower_boundary:\n",
    "            correction = []\n",
    "            for i in range(len(self.datalog['Elements'][0])):\n",
    "                if new_position[i] > self.upper_boundary:\n",
    "                    #Fill the previous column of correction by 1/(n-1) of the correction\n",
    "                    for x in range(i):\n",
    "                        correction.append(-2*(self.upper_boundary - new_position[i])/(len(self.datalog['Elements'][0])-1))\n",
    "                    #Fill column of correction\n",
    "                    correction.append(2*(self.upper_boundary - new_position[i]))\n",
    "                    #Fill the next column of correction by 1/(n-1) of the correction\n",
    "                    for x in range(len(self.datalog['Elements'][0])-1-i):\n",
    "                        correction.append(-2*(self.upper_boundary - new_position[i])/(len(self.datalog['Elements'][0])-1))\n",
    "\n",
    "                if new_position[i] < self.lower_boundary:\n",
    "                    #Fill the previous column of correction by 1/(n-1) of the correction\n",
    "                    for x in range(i):\n",
    "                        correction.append(-2*(self.lower_boundary - new_position[i])/(len(self.datalog['Elements'][0])-1))\n",
    "                    #Fill column of correction\n",
    "                    correction.append(2*(self.lower_boundary - new_position[i]))\n",
    "                    #Fill the next column of correction by 1/(n-1) of the correction\n",
    "                    for x in range(len(self.datalog['Elements'][0])-1-i):\n",
    "                        correction.append(-2*(self.lower_boundary - new_position[i])/(len(self.datalog['Elements'][0])-1))\n",
    "\n",
    "            correction = np.array(correction)\n",
    "            correction = np.reshape(correction, (int(len(correction)/len(self.datalog['Elements'][0])), len(self.datalog['Elements'][0])))\n",
    "\n",
    "            #Add the correction to the old position \n",
    "            for i in range(len(correction)):\n",
    "                 new_position = new_position + correction[i]\n",
    "        return new_position\n",
    "        \n",
    "    def update_distance(self, comparison):\n",
    "        for i in range(len(self.working_generation)):\n",
    "            self.working_generation.at[i, 'Distance'] = np.sqrt(sum((self.working_generation.at[i, 'Position']-comparison)**2))\n",
    "            self.working_generation.at[i, 'Distance'] = np.around(self.working_generation.at[i, 'Distance'], decimals = 3)\n",
    "        return\n",
    "    \n",
    "    def move(self):\n",
    "        #Updating generation\n",
    "        self.generation += 1\n",
    "        self.working_generation['Generation'] += 1\n",
    "        \n",
    "        #Updating velocity\n",
    "        self.create_new_velocity()\n",
    "        \n",
    "        #Check velocity\n",
    "        self.check_velocity()\n",
    "        \n",
    "        #Updating position\n",
    "        self.change_position()\n",
    "        \n",
    "        #Filling the \"Activity\" column\n",
    "        self.f_activity(self.working_generation)\n",
    "        \n",
    "        #Updating \"Distance\" column\n",
    "        self.update_distance(self.comparison)\n",
    "        \n",
    "        #Logging \"Possible Optima\"\n",
    "        self.possible_optima_logging()\n",
    "        \n",
    "        #Concating the tables\n",
    "        self.datalog = pd.concat([self.datalog, self.working_generation])\n",
    "        self.datalog = self.datalog.reset_index(drop=True)\n",
    "        self.store_datalog()\n",
    "        return \n",
    "\n",
    "    \n",
    "    def normalize_velocity(self):\n",
    "        for i in range(len(self.working_generation)):\n",
    "            self.working_generation.at[i, 'Velocity'] = self.working_generation.at[i, 'Velocity'] - (sum(self.working_generation.at[i, 'Velocity'])/len(self.working_generation['Elements'][0]))\n",
    "            self.working_generation.at[i, 'Velocity'] = np.around(self.working_generation.at[i, 'Velocity'], decimals= self.decimals)\n",
    "        return\n",
    "\n",
    "    \n",
    "    def limitting_velocity(self):\n",
    "        for i in range(len(self.working_generation)):\n",
    "            if np.sqrt(sum(self.working_generation.at[i, 'Velocity']**2)) > self.working_generation.at[i, 'v_max']:\n",
    "                self.working_generation.at[i, 'Velocity'] = self.working_generation.at[i, 'Velocity'] / np.sqrt(sum(self.working_generation.at[i, 'Velocity']**2)) * self.working_generation.at[i, 'v_max']\n",
    "                self.working_generation.at[i, 'Velocity'] = np.around(self.working_generation.at[i, 'Velocity'], decimals= self.decimals)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def check_velocity(self):\n",
    "        for i in range(len(self.working_generation)):\n",
    "            if np.sqrt(sum(self.datalog.loc[self.datalog['Generation'] == (self.generation-1)].reset_index().at[i, 'Velocity']**2)) < self.working_generation.at[i, 'v_min']:          \n",
    "                self.working_generation.at[i, 'Velocity'] = self.working_generation.at[i, 'Velocity'] / np.sqrt(sum(self.working_generation.at[i, 'Velocity']**2)) * self.kicking_multiplier\n",
    "                self.working_generation.at[i, 'Velocity'] = np.around(self.working_generation.at[i, 'Velocity'], decimals= self.decimals)\n",
    "        return\n",
    "    \n",
    "    \n",
    "    def mutate(self, new_velocity, mutation_rate, mutation_prob, flip_prob):\n",
    "        mutated_velocity = []\n",
    "        for i in range(len(new_velocity)):\n",
    "            #Randoming number to decide whether mutation happen or not\n",
    "            mutation = np.random.rand()\n",
    "            step_size_i = 1\n",
    "            \n",
    "            #If mutation happen\n",
    "            if mutation < mutation_prob:\n",
    "                #Randoming the number for the step size\n",
    "                step_size_i = np.random.uniform((1-mutation_rate), (1+mutation_rate))\n",
    "                \n",
    "                #Mutation and Flip\n",
    "                if mutation < flip_prob * mutation_prob:\n",
    "                    step_size_i = -1 * step_size_i\n",
    "                    \n",
    "                #Only mutation            \n",
    "                else:\n",
    "                    step_size_i = step_size_i\n",
    "            mutated_velocity.append(new_velocity[i] * step_size_i)\n",
    "        mutated_velocity = np.array(mutated_velocity)\n",
    "        \n",
    "        #Normalizing velocity\n",
    "        normal_velocity = mutated_velocity - (sum(mutated_velocity)/len(self.working_generation['Elements'][0]))\n",
    "       \n",
    "        #Preserving the magnitude of velocity before mutation with checking the normal velocity first to avoid the error\n",
    "        if np.sqrt(sum(normal_velocity**2)) == 0:\n",
    "            unit_velocity = np.zeros(len(self.working_generation['Elements'][0]))\n",
    "        else:\n",
    "            unit_velocity = normal_velocity / np.sqrt(sum(normal_velocity**2)) * np.sqrt(sum(new_velocity**2))\n",
    "        return unit_velocity\n",
    "    \n",
    "    \n",
    "    def possible_optima_logging(self):\n",
    "        for i in range(len(self.working_generation)):\n",
    "            if np.sqrt(sum(self.working_generation.at[i, 'Velocity']**2)) < 1.5 * self.grid_distance:\n",
    "                self.optima = pd.concat([self.optima, self.working_generation.loc[i:i]])\n",
    "        self.optima.to_csv('../../raw_data/composition_vs_activity/model2/PSO/log/optima_gen_' + str(self.generation) + '.txt', sep='\\t', index=False, mode='w')\n",
    "    \n",
    "    def g_best(self):\n",
    "        return self.datalog.loc[np.argmax(self.datalog['Activity'])]\n",
    "    \n",
    "    def g_closest(self):\n",
    "        return self.datalog.loc[np.argmin(self.datalog['Distance'])]\n",
    "    \n",
    "    def minimum_generation_activity(self, limit):\n",
    "        return self.datalog[self.datalog['Activity']>=limit]['Generation'].min()\n",
    "    \n",
    "    def minimum_generation_distance(self, limit):\n",
    "        return self.datalog[self.datalog['Distance']<=limit]['Generation'].min()\n",
    "    \n",
    "    def global_record_comparison(self, category):\n",
    "        if category == 'best':\n",
    "            individual = self.datalog.loc[np.argmax(self.datalog['Activity'])]\n",
    "        elif category == 'worst':\n",
    "            individual = self.datalog.loc[np.argmin(self.datalog['Activity'])]\n",
    "        return individual \n",
    "    \n",
    "    def generational_comparison(self, category):\n",
    "        if category == 'best':\n",
    "            individual = self.working_generation.loc[np.argmax(self.working_generation['Activity'])]\n",
    "        elif category == 'worst':\n",
    "            individual = self.working_generation.loc[np.argmin(self.working_generation['Activity'])]\n",
    "        return individual\n",
    "           \n",
    "    def individual_record_comparison(self, ID, category):\n",
    "        self.individual_data = self.datalog[self.datalog['ID']==ID].reset_index(drop=True)\n",
    "        if category == 'best':\n",
    "            individual = self.individual_data.loc[np.argmax(self.individual_data['Activity'])]\n",
    "        elif category == 'worst':\n",
    "            individual = self.individual_data.loc[np.argmin(self.individual_data['Activity'])]\n",
    "        return individual\n",
    "    \n",
    "    def delta_global_record(self, ID, parameter, category):\n",
    "        return self.global_record_comparison(category)[parameter] - self.working_generation[self.working_generation['ID']==ID][parameter].reset_index(drop=True)[0]\n",
    "    \n",
    "    def delta_generation(self, ID, parameter, category):\n",
    "        return self.generational_comparison(category)[parameter] - self.working_generation[self.working_generation['ID']==ID][parameter].reset_index(drop=True)[0]\n",
    "    \n",
    "    def delta_individual_record(self, ID, parameter, category):\n",
    "        return self.individual_record_comparison(ID, category)[parameter] - self.working_generation[self.working_generation['ID']==ID][parameter].reset_index(drop=True)[0]\n",
    "    \n",
    "    def individual_log(self, ID):\n",
    "        return self.datalog[self.datalog['ID']==ID].reset_index(drop=True)\n",
    "    \n",
    "    def store_datalog(self):\n",
    "        self.datalog.to_csv('../../raw_data/composition_vs_activity/model2/PSO/log/log_gen_' + str(self.generation) + '.txt', sep='\\t', index=False, mode='w')\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ddfb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b24b51ee",
   "metadata": {},
   "source": [
    "# Pay attention to initial points, comparison, boundaries, data_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ba9cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "metals = ['Ag', 'Ir', 'Pd', 'Pt', 'Ru']\n",
    "initial_magnitude_limit = 0.2\n",
    "comparison = np.array([0.15, 0., 0.85, 0., 0.])\n",
    "model_type = 'model2'\n",
    "boundaries = (0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819d08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_PSO(parameters, name):\n",
    "    for i in range (5):\n",
    "        population = pso(pd.read_csv('initial_points.txt', sep='\\t'),\n",
    "                         comparison = comparison,\n",
    "                         grid_distance = 0.106,\n",
    "                         initial_magnitude_limit = 0.2,\n",
    "                         model_type = model_type)\n",
    "        population.input_initial_parameter(parameter = 'F_damp', value = parameters[0], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_b_best', value = parameters[1], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_h_best', value = parameters[2], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_g_best', value = parameters[3], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_b_worst', value = parameters[4], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_h_worst', value = parameters[5], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'F_g_worst', value = parameters[6], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'mut_prob', value = parameters[7], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'flip_prob', value = parameters[8], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'mut_rate', value = parameters[9], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'v_max', value = parameters[10], ID = 0, behavior = 'uniform')\n",
    "        population.input_initial_parameter(parameter = 'v_min', value = parameters[11], ID = 0, behavior = 'uniform')\n",
    "        \n",
    "        for x in range(30):\n",
    "            population.move()\n",
    "        population.datalog.to_csv(name + str(i) + '.txt', sep='\\t', index=False, mode='w')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792b2235",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_model1 = [0.67, 1.95, 1.4 , 0.12, 0.07, 0.31, 0.04, 0.32, 0.17, 0.43, 0.2, 0.071]\n",
    "parameter_model2 = [0.43, 0.02, 0.07, 1.18, 1.97, 1.09, 0.22, 0.11, 0.13, 0.04, 0.2, 0.071]\n",
    "parameter_model3 = [0.63, 1.11, 1.  , 1.76, 0.08, 0.11, 0.02, 0.13, 0.54, 0.19, 0.2, 0.071]\n",
    "parameter_model4 = [0.74, 1.67, 1.76, 0.42, 0.02, 0.05, 0.01, 0.11, 0.82, 0.37, 0.2, 0.071]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcfa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_PSO(parameter_model1, '../../raw_data/composition_vs_activity/model2/PSO/PSO_0_')\n",
    "create_PSO(parameter_model2, '../../raw_data/composition_vs_activity/model2/PSO/PSO_1_')\n",
    "create_PSO(parameter_model3, '../../raw_data/composition_vs_activity/model2/PSO/PSO_2_')\n",
    "create_PSO(parameter_model4, '../../raw_data/composition_vs_activity/model2/PSO/PSO_3_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022f406",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
